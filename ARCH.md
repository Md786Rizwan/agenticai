
# Academia AI Architecture & Deployment Guide

## 1. High-Level System Architecture

```text
[Frontend: React/TS] <---> [LLM: Gemini API]
      |
      |-- [PDF Loader: PDF.js]
      |-- [Web Loader: Manual Input/Scraper]
      |-- [Chunker: Recursive Character Splitter]
      |-- [Vector Store: In-Memory (Client) -> FAISS (Production)]
      |-- [Query Engine: Subject-Filtered Search]
```

## 2. Production Technology Stack Recommendation

For scaling to thousands of students, the following transition is recommended:

- **Backend:** FastAPI (Python) for processing intensive PDF parsing and embeddings.
- **Vector DB:** ChromaDB or Pinecone for persistence.
- **Embeddings:** `text-embedding-004` (Gemini) or HuggingFace local models.
- **Queueing:** Celery/Redis for handling large PDF batch ingestion.
- **PDF Extraction:** `PyMuPDF` or `Unstructured.io` for higher fidelity than client-side JS.

## 3. Deployment Instructions

### Local Development
1. Ensure your `API_KEY` for Google AI Studio is set in your environment.
2. Run `npm install` and `npm start`.

### Production Deployment (Vercel/Netlify)
1. Push this repository to GitHub.
2. Connect the repository to Vercel/Netlify.
3. **Environment Variable:** Add `API_KEY` to the service's Environment Variables settings.
4. Set the build command to `npm run build` and the output directory to `dist`.

## 4. Scalability Considerations
- **Metadata Filtering:** The current architecture uses subject-based filtering. In a production SQL/Vector DB, ensure `subject_id` is indexed as a metadata field for O(1) filtering before semantic search.
- **Citations:** Every chunk must retain `document_id`, `page_number`, and `checksum` to prevent hallucinated citations.

## 5. Future Features
- **Math Formula Explanation:** Integrate MathJax for rendering LaTeX from Gemini responses.
- **Multi-Subject Reasoning:** Allow queries to search across multiple subject indexes simultaneously.
- **Interactive Diagrams:** Use Mermaid.js to render flowcharts generated by the AI from your notes.
